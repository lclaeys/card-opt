{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f03756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "import time\n",
    "from cvxopt import matrix,solvers\n",
    "from sklearn.covariance import EmpiricalCovariance, MinCovDet\n",
    "import yfinance as yf\n",
    "solvers.options['show_progress'] = False\n",
    "solvers.options['refinement'] = 2\n",
    "solvers.options['abstol'] = 1e-13\n",
    "solvers.options['reltol'] = 1e-13\n",
    "solvers.options['feastol'] = 1e-13\n",
    "\n",
    "import random\n",
    "import scipy\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c338257e",
   "metadata": {},
   "source": [
    "Functions required for denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d9294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPCA(matrix):\n",
    "# Get eVal,eVec from a Hermitian matrix\n",
    "    eVal,eVec=np.linalg.eigh(matrix)\n",
    "    indices=eVal.argsort()[::-1] # arguments for sorting eVal desc\n",
    "    eVal,eVec=eVal[indices],eVec[:,indices]\n",
    "    eVal=np.diagflat(eVal)\n",
    "    return eVal,eVec\n",
    "\n",
    "def fitKDE(obs,bWidth=.25,kernel='gaussian',x=None):\n",
    "    # Fit kernel to a series of obs, and derive the prob of obs\n",
    "    # x is the array of values on which the fit KDE will be evaluated\n",
    "    if len(obs.shape)==1:obs=obs.reshape(-1,1)\n",
    "    kde=KernelDensity(kernel=kernel,bandwidth=bWidth).fit(obs)\n",
    "    if x is None:x=np.unique(obs).reshape(-1,1)\n",
    "    if len(x.shape)==1:x=x.reshape(-1,1)\n",
    "    logProb=kde.score_samples(x) # log(density)\n",
    "    pdf=pd.Series(np.exp(logProb),index=x.flatten())\n",
    "    return pdf\n",
    "\n",
    "def errPDFs(var,eVal,q,bWidth,pts=1000):\n",
    "    # Fit error\n",
    "    pdf0=mpPDF(var,q,pts) # theoretical pdf\n",
    "    pdf1=fitKDE(eVal,bWidth,x=pdf0.index.values) # empirical pdf\n",
    "    sse=np.sum((pdf1-pdf0)**2)\n",
    "    return sse\n",
    "\n",
    "def findMaxEval(eVal,q,bWidth):\n",
    "    # Find max random eVal by fitting Marcenkoâ€™s dist\n",
    "    out=minimize(lambda *x:errPDFs(*x),.5,args=(eVal,q,bWidth),\n",
    "    bounds=((1E-5,1-1E-5),))\n",
    "    if out['success']:var=out[\"x\"][0]\n",
    "    else:var=1\n",
    "    eMax=var*(1+(1./q)**.5)**2\n",
    "    return eMax,var\n",
    "\n",
    "def denoisedCorr(eVal,eVec,nFacts):\n",
    "    # Remove noise from corr by fixing random eigenvalues\n",
    "    eVal_=np.diag(eVal).copy()\n",
    "    eVal_[nFacts:]=eVal_[nFacts:].sum()/float(eVal_.shape[0]-nFacts)\n",
    "    eVal_=np.diag(eVal_)\n",
    "    corr1=np.dot(eVec,eVal_).dot(eVec.T)\n",
    "    corr1=cov2corr(corr1)\n",
    "    return corr1\n",
    "    #- - - - - - - -- - - - - - - - - - - - -- - - - - - - - - - - - - -- - - - - - - - - - - - -- - -\n",
    "    corr1=denoisedCorr(eVal0,eVec0,nFacts0)\n",
    "    eVal1,eVec1=getPCA(corr1)\n",
    "    \n",
    "def atf(x):\n",
    "    if isinstance(x,np.ndarray):\n",
    "        x = x.item()\n",
    "    return x\n",
    "\n",
    "def mpPDF(var,q,pts=1000):\n",
    "    # Marcenko-Pastur pdf\n",
    "    # q=T/N\n",
    "    eMin=atf(var*(1-(1/q)**.5)**2)\n",
    "    eMax=atf(var*(1+(1/q)**.5)**2)\n",
    "\n",
    "    eVal=np.linspace(eMin,eMax,pts)\n",
    "    #display(eVal)\n",
    "    pdf=q/(2*np.pi*var*eVal)*((eMax-eVal)*(eVal-eMin))**.5\n",
    "    pdf=pd.Series(pdf,index=eVal)\n",
    "    return pdf\n",
    "\n",
    "def cov2corr(cov):\n",
    "    # Derive the correlation matrix from a covariance matrix\n",
    "    std=np.sqrt(np.diag(cov))\n",
    "    corr=cov/np.outer(std,std)\n",
    "    corr[corr<-1],corr[corr>1]=-1,1 # numerical error\n",
    "    return corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940c9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimiser:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def load_feather(self,file1,file2=\"\",T0=0,N0=0,N=48,T=-1,normalize=False):\n",
    "        self.data = pd.read_feather(file1).iloc[T0:T]\n",
    "        self.universe = pd.read_feather(file2).iloc[N0:N]\n",
    "        self.assets = self.data.columns[1+N0:N+1]\n",
    "        # T x N matrix of closing prices \n",
    "        self.prices = np.zeros([len(self.data),len(self.assets)])            \n",
    "        for i in range(len(self.assets)):\n",
    "            self.prices[:,i] = self.data[self.assets[i]]\n",
    "            if normalize == True:\n",
    "                self.prices[:,i] = self.prices[:,i]/self.prices[0,i]\n",
    "        self.price_data = self.prices\n",
    "        \n",
    "        # mean returns, averaged logarithmic returns\n",
    "        self.mean_returns = (self.prices[-1,:] - self.prices[0,:])/len(self.prices[:,0])*1000\n",
    "        self.log_returns = np.mean(np.log(self.prices[1:,:]/self.prices[:-1,:]),axis=0)\n",
    "        self.naive_cov = np.cov(np.transpose(self.prices))\n",
    "        #self.robust_cov = MinCovDet().fit(opt.prices).covariance_\n",
    "        self.cov = self.naive_cov\n",
    "        self.diffs = self.prices[1:]-self.prices[:-1]\n",
    "        \n",
    "    def simulate_portfolios(self, N=100, norm = 1,method=\"mean\"):\n",
    "        mean = np.zeros(len(self.assets))\n",
    "        mean = opt.maximum_sharpe()[0]\n",
    "        #mean = opt.minimum_variance()[0]\n",
    "        lr = []\n",
    "        vol = []\n",
    "        r = np.random.uniform(-1,1,size=[len(self.assets),N])\n",
    "        for i in range(N):\n",
    "            r[:,i] = mean + r[:,i]/norm\n",
    "            lr.append(Optimiser.mean_returns(self.prices,r[:,i],method))\n",
    "            vol.append(Optimiser.naive_vol(self.prices,r[:,i]))\n",
    "        data = {\n",
    "            'returns': lr,\n",
    "            'volatility': vol\n",
    "        }\n",
    "        return pd.DataFrame(data)\n",
    "    \n",
    "    def minimum_variance(self):\n",
    "        var = np.cov(np.transpose(self.prices))\n",
    "        a = np.ones(len(self.assets))\n",
    "        x = np.linalg.solve(var,a)\n",
    "        allocation = x/a.dot(x)\n",
    "        return allocation, Optimiser.mean_returns(self.prices,allocation,\"mean\"), Optimiser.naive_vol(self.prices,allocation)\n",
    "    \n",
    "    def maximum_sharpe(self):\n",
    "        var = np.cov(np.transpose(self.prices))\n",
    "        a = self.mean_returns\n",
    "        #a = self.log_returns\n",
    "        x = np.linalg.solve(var,a)\n",
    "        allocation = x/a.dot(x)\n",
    "        #allocation = allocation/sum(allocation)\n",
    "        return allocation, Optimiser.mean_returns(self.prices,allocation,\"mean\"), Optimiser.naive_vol(self.prices,allocation)\n",
    "    \n",
    "    def gradient_descent_opt(self, w0,constraints=[],cost_func = \"volatility\",stepmethod = [\"constant\",1e-6],N=100,eps = 1e-10,benchmark = 0):\n",
    "        V = self.cov\n",
    "        mu = self.mean_returns\n",
    "        \n",
    "        def cost(w):\n",
    "            if cost_func == \"volatility\":\n",
    "                return self.vol(w)\n",
    "            elif cost_func == \"sharpe\":\n",
    "                return -self.sharpe(w)\n",
    "            elif cost_func == \"benchmark\":\n",
    "                return np.linalg.norm(self.prices.dot(w)-benchmark)**2\n",
    "        \n",
    "        def calc_grad(w):\n",
    "            if cost_func == \"volatility\":\n",
    "                return 2*V.dot(w)\n",
    "            elif cost_func == \"sharpe\":\n",
    "                return -(mu-mu.dot(w)*V.dot(w)/self.vol(w))/np.sqrt(self.vol(w))\n",
    "            elif cost_func == \"benchmark\":\n",
    "                return 2*(self.prices.dot(w)-benchmark).dot(self.prices)\n",
    "            \n",
    "        def projection(x):\n",
    "            if \"longonly1\" in constraints:\n",
    "                for j in range(len(x)):\n",
    "                    x[j] = abs(x[j])\n",
    "            if \"longonly2\" in constraints:\n",
    "                for j in range(len(x)):\n",
    "                    x[j] = max(x[j],0)\n",
    "            \n",
    "            if \"shortonly2\" in constraints:\n",
    "                for j in range(len(x)):\n",
    "                    x[j] = min(x[j],0)\n",
    "            \n",
    "            if \"sum1\" in constraints:\n",
    "                x = x/sum(x)\n",
    "                \n",
    "            if \"sum-1\" in constraints:\n",
    "                x = -x/sum(x)\n",
    "                \n",
    "            return x\n",
    "        \n",
    "        i = 0\n",
    "        w = [projection(w0)]\n",
    "        grad = 10\n",
    "        while i < N and np.linalg.norm(grad) > eps:\n",
    "            wcurrent = w[-1]\n",
    "            grad = calc_grad(wcurrent)\n",
    "            p = -grad/np.linalg.norm(grad)\n",
    "            \n",
    "            if stepmethod[0] == \"constant\":\n",
    "                step = np.linalg.norm(grad)*stepmethod[1]\n",
    "                \n",
    "            elif stepmethod[0] == \"armijo\":\n",
    "                c = stepmethod[1]\n",
    "                tau = stepmethod[2]\n",
    "                m = grad.dot(p)\n",
    "                step = -c*m\n",
    "                if m > 0:\n",
    "                    print(\"No descent?\")\n",
    "                while cost(wcurrent)-cost(wcurrent+step*p) <= -step*c*m:\n",
    "                    step = tau*step\n",
    "                    \n",
    "            wnext = projection(wcurrent + p*step)\n",
    "            w.append(wnext)\n",
    "            i+=1\n",
    "        return w\n",
    "    \n",
    "    def cardinality_opt(self,M,rho,alfa,cost_func,limit_attempts = False, attempts = 20):\n",
    "        N = len(self.assets)\n",
    "        T = len(self.prices)\n",
    "        \n",
    "        self.mean_returns = (self.prices[-1,:] - self.prices[0,:])/len(self.prices[:,0])*1000\n",
    "        self.naive_cov = np.cov(np.transpose(self.prices))\n",
    "        P = self.naive_cov\n",
    "        q = np.matrix(-alfa*rho*self.mean_returns)\n",
    "        e = np.matrix(np.ones(N))\n",
    "        C = P+np.transpose(e).dot(q)+np.transpose(q).dot(e)\n",
    "        return Optimiser.cardinality_optimise(C,M,limit_attempts = limit_attempts, attempts = attempts)\n",
    "    \n",
    "    def cardinality_benchmark(self,benchmark,M):\n",
    "        N = len(self.assets)\n",
    "        T = len(self.prices)\n",
    "        \n",
    "        P = self.prices.transpose().dot(self.prices)\n",
    "        q = -np.matrix(benchmark.dot(self.prices))\n",
    "        e = np.matrix(np.ones(N))\n",
    "        C = P+np.transpose(e).dot(q)+np.transpose(q).dot(e)\n",
    "        return Optimiser.cardinality_optimise(C,M)\n",
    "        \n",
    "    def l1_cardinality_benchmark(self,benchmark,cardinality,constraints):\n",
    "        M = cardinality\n",
    "        N = len(self.assets)\n",
    "        T = len(self.prices)\n",
    "        a = [1]\n",
    "        done = False\n",
    "        constraints.append(\"L1\")\n",
    "        ws = np.round(np.array(self.cvx_opt(constraints,\"benchmark\",benchmark=benchmark,parameter = a[-1])),3)\n",
    "        nums = np.array([len(ws[ws>0])])\n",
    "        \n",
    "        i=0\n",
    "        while np.all(nums > M) and i < 20:\n",
    "            a.append(a[-1]*2)\n",
    "            w = np.round(np.array(self.cvx_opt(constraints,\"benchmark\",benchmark=benchmark,parameter = a[-1])),3)\n",
    "            ws = np.append(ws,w)\n",
    "            nums = np.append(nums,len(w[w>0]))\n",
    "            i+=1\n",
    "                \n",
    "        while np.all(nums < M) and i < 20:\n",
    "            a.append(a[-1]/2)\n",
    "            w = np.round(np.array(self.cvx_opt(constraints,\"benchmark\",benchmark=benchmark,parameter = a[-1])),3)\n",
    "            ws = np.append(ws,w)\n",
    "            nums = np.append(nums,len(w[w>0]))\n",
    "            i+=1\n",
    "        i = 0\n",
    "        while not done:\n",
    "            i+=1\n",
    "            if len(a) > 1:\n",
    "                if min(nums[-1],nums[-2]) <= M and M <= max(nums[-1],nums[-2]):\n",
    "                    a.append((a[-1]+a[-2])/2)\n",
    "                elif min(nums[-1],nums[-3]) <= M and M <= max(nums[-1],nums[-3]):\n",
    "                    a[-2] = a[-3]\n",
    "                    nums[-2] = nums[-3]\n",
    "                    a.append((a[-1]+a[-3])/2)\n",
    "                else:\n",
    "                    a.append(a[-1])\n",
    "            else:\n",
    "                a.append(a[-1])\n",
    "            w = np.round(np.array(self.cvx_opt(constraints,\"benchmark\",benchmark=benchmark,parameter = a[-1])),3)\n",
    "            ws = np.append(ws,w)\n",
    "            nums = np.append(nums,len(w[w>0]))\n",
    "            \n",
    "            if nums[-1] == M or i == 10:\n",
    "                \n",
    "                # retrieve last time n <= M to continue\n",
    "                \n",
    "                lastlower_index = np.where(nums<=M)[0][-1]\n",
    "                a.append(a[lastlower_index])\n",
    "                w = np.round(np.array(self.cvx_opt(constraints,\"benchmark\",benchmark=benchmark,parameter = a[-1])),3)\n",
    "                ws = np.append(ws,w)\n",
    "                nums = np.append(nums,len(w[w>0]))\n",
    "                \n",
    "                j = 0\n",
    "                while nums[-1] <= M and j <= 20:\n",
    "                    f = 0.99\n",
    "                    w = np.round(np.array(self.cvx_opt(constraints,\"benchmark\",benchmark=benchmark,parameter = a[-1]*f)),3)\n",
    "                    if len(w[w>0]) <= M:\n",
    "                        ws = np.append(ws,w)\n",
    "                        nums = np.append(nums,len(w[w>0]))\n",
    "                        a.append(a[-1]*f)\n",
    "                    j+=1\n",
    "                done = True\n",
    "        ws = ws.reshape(len(ws)//len(self.assets),len(self.assets))\n",
    "        self.benchmark = benchmark\n",
    "        #return ws, nums, a    \n",
    "        return self.cvx_opt(cost_func=\"benchmark\",constraints=constraints,benchmark=benchmark,sparsity=ws[-1])\n",
    "        \n",
    "    def monte_carlo_cardinality(self,constraints,cost_func,selection = [], benchmark = [], adjust = (0,0),debug=False, parameter = 0,minreturn = 0,maxsum=1,sparsity = [], cardinality = 0, time = [0,None], minallocation = 0,simulations=100):\n",
    "        self.benchmark = benchmark\n",
    "        N = len(self.assets)\n",
    "        bestw = 0\n",
    "        lowestcost = 1e10\n",
    "        n = np.array(range(N))\n",
    "        \n",
    "        for j in range(simulations):\n",
    "            sample = np.random.choice(n, M)\n",
    "            sparsity = np.array([int(i in sample) for i in range(N)])\n",
    "            w = self.cvx_opt(constraints,cost_func,selection, benchmark, adjust,debug,parameter,minreturn,maxsum,sparsity,cardinality,time,minallocation)\n",
    "            c = self.cost(w,cost_func)\n",
    "            lowestcost = min(lowestcost,c)\n",
    "            if c == lowestcost:\n",
    "                bestw = w\n",
    "        return bestw\n",
    "    \n",
    "    def brute_cardinality(self,constraints,cost_func,selection = [], benchmark = [], adjust = (0,0),debug=False, parameter = 0,minreturn = 0,maxsum=1,sparsity = [], cardinality = 0, time = [0,None], minallocation = 0):\n",
    "        N = len(self.assets)\n",
    "        def power_set(input):\n",
    "        # returns a list of all subsets of the list a\n",
    "            if (len(input) == 0):\n",
    "                return [[]]\n",
    "            main_subset = [ ]\n",
    "            for small_subset in power_set(input[1:]):\n",
    "                main_subset += [small_subset]\n",
    "                main_subset += [[input[0]] + small_subset]\n",
    "            return main_subset\n",
    "        sets = power_set(np.arange(0,N))\n",
    "        exactsets = []\n",
    "        for i in sets:\n",
    "            if len(i) == cardinality:\n",
    "                exactsets.append(i)\n",
    "        \n",
    "        curmin = 1e10\n",
    "        curbestw = np.zeros(N)\n",
    "        for I in exactsets:\n",
    "            sparsity = np.array([int(i in I) for i in range(N)])\n",
    "            w = self.cvx_opt(constraints,cost_func,selection, benchmark, adjust,debug,parameter,minreturn,maxsum,sparsity,cardinality,time,minallocation)\n",
    "            cost = self.cost(w,cost_func)\n",
    "            if cost <= curmin:\n",
    "                curmin = cost\n",
    "                curbestw = w\n",
    "        return curbestw\n",
    "    \n",
    "    def greedy_cardinality(self,constraints,cost_func,selection = [], benchmark = [], adjust = (0,0),debug=False, parameter = 0,minreturn = 0,maxsum=1,sparsity = [], cardinality = 0, quick = True, time = [0,None],min_change = 0.0001,strict=False, minallocation = 0):\n",
    "        curmin = 1e10\n",
    "        curminindex = 0\n",
    "        N = len(self.assets)\n",
    "        n = set(np.arange(N))\n",
    "        I = np.array([])\n",
    "        update = True\n",
    "        while I.size < cardinality and update == True:\n",
    "            update = False\n",
    "            if strict:\n",
    "                curmin = 1e10\n",
    "            for i in n:\n",
    "                I_ = np.append(I,i)\n",
    "                sparsity = np.array([int(i in I_) for i in range(N)])\n",
    "                wi = self.cvx_opt(constraints,cost_func,selection, benchmark, adjust,debug,parameter,minreturn,maxsum,sparsity,cardinality,time,minallocation)\n",
    "                costi = self.cost(wi, cost_func)\n",
    "                if costi <= curmin*(1-min_change) and self.returns(wi) >= minreturn:\n",
    "                    curmin = costi\n",
    "                    curminindices = I_\n",
    "                    addedindex = i\n",
    "                    update = True\n",
    "            if update:\n",
    "                I = curminindices\n",
    "                n.remove(addedindex)\n",
    "                if debug:\n",
    "                    print(\"Current best indices: \" + str(np.sort(I)))\n",
    "                    print(\"Current lowest cost: \" + str(curmin))\n",
    "            if quick == False and update:\n",
    "                while update == True:\n",
    "                    update = False\n",
    "                    for k in I:\n",
    "                        for i in n:\n",
    "                            I_ = I[I!=k]\n",
    "                            I_ = np.append(I_,i)\n",
    "                            sparsity = np.array([int(i in I_) for i in range(N)])\n",
    "                            wi = self.cvx_opt(constraints,cost_func,selection, benchmark, adjust,debug,parameter,minreturn,maxsum,sparsity,cardinality,time,minallocation)\n",
    "                            costi = self.cost(wi, cost_func)\n",
    "                            if costi < curmin*(1-min_change) and self.returns(wi) >= minreturn:\n",
    "                                curmin = costi\n",
    "                                addedindex = i\n",
    "                                removedindex = k\n",
    "                                curminindices = I_\n",
    "                                update = True\n",
    "                    if update:\n",
    "                        n.remove(addedindex)\n",
    "                        n.add(removedindex)\n",
    "                        I = curminindices\n",
    "                        if debug:\n",
    "                            print(\"Current best indices: \" + str(np.sort(I)))\n",
    "                            print(\"Current lowest cost: \" + str(curmin))\n",
    "                update = True\n",
    "        update = True\n",
    "        \n",
    "        while update == True:\n",
    "            update = False\n",
    "            for k in I:\n",
    "                for i in n:\n",
    "                    I_ = I[I!=k]\n",
    "                    I_ = np.append(I_,i)\n",
    "                    sparsity = np.array([int(i in I_) for i in range(N)])\n",
    "                    wi = self.cvx_opt(constraints,cost_func,selection, benchmark, adjust,debug,parameter,minreturn,maxsum,sparsity,cardinality,time,minallocation)\n",
    "                    costi = self.cost(wi, cost_func)\n",
    "                    if costi < curmin*(1-min_change) and self.returns(wi) >= minreturn:\n",
    "                        curmin = costi\n",
    "                        addedindex = i\n",
    "                        removedindex = k\n",
    "                        curminindices = I_\n",
    "                        update = True\n",
    "            if update:\n",
    "                n.remove(addedindex)\n",
    "                n.add(removedindex)\n",
    "                I = curminindices\n",
    "                if debug:\n",
    "                    print(\"Current best indices: \" + str(np.sort(I)))\n",
    "                    print(\"Current lowest cost: \" + str(curmin))\n",
    "        sparsity = np.array([int(i in I) for i in range(N)])\n",
    "        return self.cvx_opt(constraints,cost_func,selection, benchmark, adjust,debug,parameter,minreturn,maxsum,sparsity,cardinality,time,minallocation)\n",
    "            \n",
    "        \n",
    "    def cvx_opt(self,constraints,cost_func,selection = [], benchmark = [], adjust = (0,0),debug=False, parameter = 0,minreturn = 0,maxsum=1,sparsity = [], cardinality = 0, time = [0,None], minallocation = 0):\n",
    "        #expected return, sharpe, VaR, MAD\n",
    "        #cost function\n",
    "        if len(benchmark) > 0:\n",
    "            self.benchmark = benchmark[time[0]:time[1]]\n",
    "        self.prices = self.price_data[time[0]:time[1],:]\n",
    "        self.fullassets = self.assets\n",
    "        self.fullprices = self.prices\n",
    "        if len(sparsity) > 0:\n",
    "            indices = []\n",
    "            for i in range(len(self.assets)):\n",
    "                if np.round(sparsity[i],5) != 0:\n",
    "                    indices.append(i)\n",
    "            if len(indices) == 1:\n",
    "                return sparsity/max(sparsity)\n",
    "            self.assets = self.fullassets[indices]\n",
    "            self.prices = self.fullprices[:,indices]\n",
    "            if adjust[1] != 0:\n",
    "                adjust = (adjust[0][indices],adjust[1])\n",
    "        \n",
    "        \n",
    "        N = len(self.assets)\n",
    "        T = len(self.prices)\n",
    "        \n",
    "        \n",
    "        self.mean_returns = (self.prices[-1,:] - self.prices[0,:])/len(self.prices[:,0])*1000\n",
    "        self.naive_cov = np.cov(np.transpose(self.prices))\n",
    "        self.cov = self.naive_cov\n",
    "        self.diffs = self.prices[1:]-self.prices[:-1]\n",
    "        \n",
    "        if cost_func == \"volatility\":\n",
    "            Q = np.cov(np.transpose(self.prices))\n",
    "            q = np.zeros(N)\n",
    "        elif cost_func == \"emp_volatility\":\n",
    "            Q = EmpiricalCovariance().fit(self.prices).covariance_\n",
    "            q = np.zeros(N)\n",
    "        elif cost_func == \"robust_volatility\":\n",
    "            Q = MinCovDet().fit(self.prices).covariance_\n",
    "            q = np.zeros(N)\n",
    "        elif cost_func == \"denoised_volatility\":\n",
    "            if N >= 3:\n",
    "                Q = Optimiser.denoised_cov(self.prices)\n",
    "            else:\n",
    "                Q = np.cov(np.transpose(self.prices))\n",
    "            q = np.zeros(N)\n",
    "        elif cost_func == \"benchmark\":\n",
    "            Q = self.prices.transpose().dot(self.prices)\n",
    "            q = -self.benchmark.dot(self.prices)\n",
    "        elif cost_func == \"expected_return\":\n",
    "            Q = np.zeros([N,N])\n",
    "            q = -self.mean_returns\n",
    "        elif cost_func == \"sharpe\":\n",
    "            Q = np.zeros([N+1,N+1])\n",
    "            Q[:N,:N] = self.cov\n",
    "            q = np.zeros(N+1)\n",
    "        elif cost_func == \"MAD\":\n",
    "            T = T-1\n",
    "            Q = np.zeros([N+T,N+T])\n",
    "            q = np.zeros(N+T)\n",
    "            q[N:] = np.ones(T)\n",
    "        \n",
    "        #constraints\n",
    "        G = np.array([])\n",
    "        h = np.array([])\n",
    "        A = np.array([])\n",
    "        b = np.array([])\n",
    "        if \"longonly\" in constraints:\n",
    "            G = np.append(G,-np.eye(len(self.assets)))\n",
    "            h = np.append(h,np.zeros(len(self.assets)))\n",
    "            \n",
    "        if \"sum1\" in constraints:\n",
    "            A = np.append(A,np.ones(len(self.assets)))\n",
    "            b = np.append(b,1)\n",
    "        \n",
    "        if \"minreturn\" in constraints:\n",
    "            G = np.append(G,-self.mean_returns)\n",
    "            h = np.append(h,-minreturn)\n",
    "        \n",
    "        if \"return\" in constraints:\n",
    "            A = np.append(A,self.mean_returns)\n",
    "            b = np.append(b,minreturn)\n",
    "        \n",
    "        if \"maxsum\" in constraints:\n",
    "            G = np.append(G,np.ones(len(self.assets)))\n",
    "            h = np.append(h,maxsum)\n",
    "        \n",
    "        if \"select\" in constraints:\n",
    "            C = np.zeros([len(selection),len(self.assets)])\n",
    "            for j in range(len(selection)):\n",
    "                neg = 0\n",
    "                if selection[j][1][0] == \"!\":\n",
    "                    selection[j][1] = selection[j][1][1:]\n",
    "                    neg = 1\n",
    "                for i in range(len(self.assets)):\n",
    "                    if self.universe.iloc[i][selection[j][0]]==selection[j][1]:\n",
    "                        C[j,i] = 1\n",
    "                if neg == 1:\n",
    "                    C[j,:] = np.abs(C[j,:]-1)\n",
    "            for j in range(len(selection)):\n",
    "                if selection[j][2] == \"=\":\n",
    "                    A = np.append(A,C[j,:])\n",
    "                    b = np.append(b,selection[j][3])\n",
    "                if selection[j][2] == \"<=\":\n",
    "                    G = np.append(G,C[j,:])\n",
    "                    h = np.append(h,selection[j][3])\n",
    "                if selection[j][2] == \">=\":\n",
    "                    G = np.append(G,-C[j,:])\n",
    "                    h = np.append(h,-selection[j][3])\n",
    "        \n",
    "        if minallocation > 0:\n",
    "            G = np.append(G,-np.eye(len(self.assets)))\n",
    "            h = np.append(h,-np.ones(len(self.assets))*minallocation)\n",
    "        \n",
    "        # not compatible with sharpe\n",
    "        if \"adjust\" in constraints:\n",
    "            Q = Q + np.eye(len(self.assets))*adjust[1]\n",
    "            q = q + -2*adjust[1]*np.array(adjust[0])\n",
    "        \n",
    "        G = G.reshape(-1,len(self.assets))\n",
    "        A = A.reshape(-1,len(self.assets))\n",
    "        \n",
    "        if cost_func == \"sharpe\":\n",
    "            A_ = np.zeros([len(A)+1,len(A[0])+1])\n",
    "            b_ = np.zeros(len(A)+1)\n",
    "            A_[:len(A),:len(A[0])] = A\n",
    "            A_[:len(A),len(A[0])] = -b\n",
    "            A_[len(A),:len(A[0])] = self.mean_returns\n",
    "            b_[len(A)] = 1\n",
    "            \n",
    "            G_ = np.zeros([len(G)+1,len(G[0])+1])\n",
    "            h_ = np.zeros(len(G)+1)\n",
    "            G_[:len(G),:len(G[0])] = G\n",
    "            G_[:len(G),len(G[0])] = -h\n",
    "            G_[len(G),len(G[0])] = -1\n",
    "            \n",
    "            A = A_\n",
    "            b = b_\n",
    "            G = G_\n",
    "            h = h_\n",
    "        \n",
    "        if cost_func == \"MAD\":\n",
    "            A_ = np.zeros([len(A),N+T])\n",
    "            A_[:,:N] = A\n",
    "            G_ = np.zeros([len(G)+2*T,N+T])\n",
    "            h_ = np.zeros(len(G)+2*T)\n",
    "            G_[:len(G),:N] = G\n",
    "            h_[:len(G)] = h\n",
    "            for i in range(T):\n",
    "                G_[len(G)+2*i,:N] = self.diffs[i]-self.mean_returns\n",
    "                G_[len(G)+2*i,N+i] = -1\n",
    "                G_[len(G)+2*i+1,:N] = -self.diffs[i]+self.mean_returns\n",
    "                G_[len(G)+2*i+1,N+i] = -1\n",
    "            A = A_\n",
    "            G = G_\n",
    "            h = h_\n",
    "            \n",
    "        if \"L1\" in constraints:\n",
    "            Q_ = np.zeros([len(Q)+N,len(Q)+N])\n",
    "            Q_[:len(Q),:len(Q)] = Q\n",
    "            q_ = np.zeros(len(q)+N)\n",
    "            q_[:len(q)] = q\n",
    "            q_[len(q):] = parameter*np.ones(N)\n",
    "            \n",
    "            A_ = np.zeros([len(A),2*N])\n",
    "            A_[:,:N] = A\n",
    "            G_ = np.zeros([len(G)+2*N,2*N])\n",
    "            h_ = np.zeros(len(G)+2*N)\n",
    "            G_[:len(G),:N] = G\n",
    "            h_[:len(G)] = h\n",
    "            for i in range(N):\n",
    "                G_[len(G)+2*i,N+i] = -1  \n",
    "                G_[len(G)+2*i,i] = 1\n",
    "                G_[len(G)+2*i+1,N+i] = -1  \n",
    "                G_[len(G)+2*i+1,i] = -1\n",
    "            A = A_\n",
    "            G = G_\n",
    "            h = h_\n",
    "            Q = Q_\n",
    "            q = q_\n",
    "            \n",
    "        if \"L2\" in constraints:\n",
    "            Q = Q + np.eye(len(Q))*parameter\n",
    "        \"\"\"Q = np.matrix(Q)\n",
    "        q = np.matrix(q)\n",
    "        G = np.matrix(G)\n",
    "        h = np.matrix(h)\n",
    "        A = np.matrix(A)\n",
    "        b = np.matrix(b)\"\"\"\n",
    "        \n",
    "        \n",
    "        Q = matrix(Q)\n",
    "        q = matrix(q)\n",
    "        G = matrix(G)\n",
    "        h = matrix(h)\n",
    "        A = matrix(A)\n",
    "        b = matrix(b)\n",
    "        \n",
    "        \n",
    "        if cost_func in [\"MAD\",\"expected_return\"]:\n",
    "            sol = solvers.lp(q,G,h,A,b)\n",
    "        else:\n",
    "            #for i in (Q, q, G, h, A, b):\n",
    "            #    print(i)\n",
    "            sol = solvers.qp(Q, q, G, h, A, b)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #if debug == True:\n",
    "        #    solution = sol\n",
    "        if cost_func == \"sharpe\":\n",
    "            solution = np.array(sol['x'])[:-1,0]/np.array(sol['x'])[-1,0]\n",
    "        elif cost_func == \"MAD\" or \"L1\" in constraints:\n",
    "            solution = np.array(sol['x'])[:N,0]\n",
    "        else:\n",
    "            solution = np.array(sol['x'])[:,0]\n",
    "        \n",
    "        if len(sparsity) > 0:\n",
    "            sol = np.zeros(len(self.fullassets))\n",
    "            for i in range(len(indices)):\n",
    "                sol[indices[i]] = solution[i]\n",
    "            solution = sol\n",
    "        self.assets = self.fullassets\n",
    "        self.prices = self.fullprices\n",
    "        \n",
    "        if \"cardinality\" in constraints:\n",
    "            reduced_w = np.zeros(len(solution))\n",
    "            for i in range(cardinality):\n",
    "                reduced_w[np.argmax(solution)] = np.max(solution)\n",
    "                solution[np.argmax(solution)] = 0\n",
    "            if \"sum1\" in constraints:\n",
    "                return reduced_w/sum(reduced_w)\n",
    "            return reduced_w\n",
    "        return solution\n",
    "        \n",
    "    def cost(self,x,cost_func,time=[0,None]):\n",
    "        if cost_func == \"volatility\":\n",
    "            Q = np.cov(np.transpose(self.prices))\n",
    "            return x.dot(Q).dot(np.transpose(x))\n",
    "        elif cost_func == \"emp_volatility\":\n",
    "            Q = EmpiricalCovariance().fit(self.prices).covariance_\n",
    "            return x.dot(Q).dot(np.transpose(x))\n",
    "        elif cost_func == \"robust_volatility\":\n",
    "            Q = MinCovDet().fit(self.prices).covariance_\n",
    "            return x.dot(Q).dot(np.transpose(x))\n",
    "        elif cost_func == \"denoised_volatility\":\n",
    "            if len(x) >= 3:\n",
    "                Q = Optimiser.denoised_cov(self.prices)\n",
    "            else:\n",
    "                Q = np.cov(np.transpose(self.prices))\n",
    "            return x.dot(Q).dot(np.transpose(x))\n",
    "        elif cost_func == \"benchmark\":\n",
    "            return np.linalg.norm(self.prices.dot(x)-self.benchmark)\n",
    "        elif cost_func == \"expected_return\":\n",
    "            Q = np.zeros([N,N])\n",
    "            q = -self.mean_returns\n",
    "            x.dot(Q).dot(np.transpose(x))+2*x.dot(q)\n",
    "        elif cost_func == \"MAD\":\n",
    "            self.diffs = self.prices[1:]-self.prices[:-1]\n",
    "            #display([abs(self.diffs[i]-self.mean_returns.dot(x)) for i in range(len(self.assets)-1)])\n",
    "            return sum([abs(self.diffs[i].dot(x)-self.mean_returns.dot(x)) for i in range(len(self.assets)-1)])\n",
    "        \n",
    "    def lowerbound(C,K):\n",
    "            alfa = np.min(C)\n",
    "            d = sorted(np.diag(C))\n",
    "            if alfa in d:\n",
    "                return alfa\n",
    "            K = min(K,len(d))\n",
    "            return alfa + 1/np.sum(1/(d[:K]-np.ones(K)*alfa))\n",
    "        \n",
    "    def cardinality_optimise(C,M,limit_attempts = True, attempts = 20):\n",
    "        M = M+1\n",
    "        def submatrix(M,indices):\n",
    "            return M[np.ix_(sorted(indices),sorted(indices))]\n",
    "\n",
    "        def C_I(C,I):\n",
    "            res = np.zeros([len(C),len(C)])\n",
    "            for i in I:\n",
    "                for j in I:\n",
    "                    res[i,j] = C[i,j]\n",
    "            return res\n",
    "\n",
    "        def is_pd(K):\n",
    "            try:\n",
    "                np.linalg.cholesky(K)\n",
    "                return 1 \n",
    "            except np.linalg.linalg.LinAlgError as err:\n",
    "                if 'Matrix is not positive definite' in err.args[0]:\n",
    "                    return 0\n",
    "                else:\n",
    "                    raise\n",
    "\n",
    "        # optimise x'Cx under the constraint supp(x) <= M\n",
    "        n = len(C)\n",
    "        N = np.arange(n)\n",
    "        # index sets\n",
    "        S_next = [[i] for i in N]\n",
    "        mins = [np.min(np.diag(C))]\n",
    "        minargs = [tuple([np.argmin(np.diag(C))])]\n",
    "        minvecs = [[1]]\n",
    "        \n",
    "        # iterate\n",
    "        for i in range(2,M):\n",
    "            update = False\n",
    "            S = S_next.copy()\n",
    "            S_next = []\n",
    "            curmin = mins[-1]\n",
    "            curminargs = minargs[-1]\n",
    "            curminvec = minvecs[-1]\n",
    "            done = set()\n",
    "            for I in S:\n",
    "                J = np.setdiff1d(N,I)\n",
    "                # find pos def candidates\n",
    "                cand = J\n",
    "                for j in J:\n",
    "                    k = 0\n",
    "                    while k < len(I):\n",
    "                        if is_pd(submatrix(C,[j,I[k]])):\n",
    "                            k+=1\n",
    "                        else:\n",
    "                            k = len(I)\n",
    "                            cand = cand[cand!=j]\n",
    "                lower = Optimiser.lowerbound(submatrix(C,np.union1d(cand,I)),M)\n",
    "                if lower < curmin:\n",
    "                    if limit_attempts:\n",
    "                        cand = np.random.choice(cand,min(attempts,len(cand)),replace=False)\n",
    "                    for j in cand:\n",
    "                        # find next point\n",
    "                        I_next = tuple(np.sort(np.append(I,j)))\n",
    "                        if I_next not in done:\n",
    "                            done.add(I_next)\n",
    "                            C_I = submatrix(C,I_next)\n",
    "                            e = np.ones(len(I_next))\n",
    "                            xmin = (e.dot(np.linalg.inv(C_I)).dot(np.transpose(e)))**(-1)*(np.linalg.inv(C_I)).dot(np.transpose(e))\n",
    "                            if np.all((xmin>0)):\n",
    "                                xcost = xmin.dot(C_I).dot(np.transpose(xmin))\n",
    "                                #display([I,xcost,curmin])\n",
    "                                curmin = min(curmin,xcost)\n",
    "                                if curmin == xcost:\n",
    "                                    curminargs = I_next\n",
    "                                    curminvec = xmin\n",
    "                                    update = True\n",
    "                                S_next.append(I_next)\n",
    "                else:\n",
    "                    #display(\"lower bound used\")\n",
    "                    pass\n",
    "\n",
    "            if update:\n",
    "                mins.append(np.array(curmin))\n",
    "                minargs.append(curminargs)\n",
    "                minvecs.append(np.array(curminvec))\n",
    "            #display([curmin,curminargs,curminvec])\n",
    "        \n",
    "        w = np.zeros(n)\n",
    "        #display(\"minargs: \" + str(minargs) + \". minvecs:\"+ str(minvecs))\n",
    "        for i in range(len(minargs[-1])):\n",
    "            w[minargs[-1][i]] = minvecs[-1][0][i]\n",
    "        return w\n",
    "   \n",
    "    \n",
    "    def time_subset_portfolio(self,t0,dt,constraints,cost_func,selection = [], benchmark = 0):\n",
    "        self.prices_temp = self.prices\n",
    "        self.prices = self.prices_temp[t0:t0+dt]\n",
    "        optw = opt.cvx_opt(constraints,cost_func,selection)\n",
    "        self.prices = self.prices_temp\n",
    "        return optw\n",
    "    \n",
    "    def portfolio_sum(self,allocation,selection):\n",
    "        s = 0\n",
    "        for i in range(len(allocation)):\n",
    "            if self.universe.iloc[i][selection[0]] == selection[1]:\n",
    "                s += allocation[i]\n",
    "        return s\n",
    "    # volatility of allocation\n",
    "    def vol(self,allocation):\n",
    "        return allocation.dot(self.cov).dot(allocation)\n",
    "    \n",
    "    # sharpe ratio of allocation\n",
    "    def sharpe(self,allocation):\n",
    "        return allocation.dot(self.mean_returns)/np.sqrt(self.vol(allocation))\n",
    "    \n",
    "    def returns(self, allocation):\n",
    "        self.mean_returns = (self.prices[-1,:] - self.prices[0,:])/len(self.prices[:,0])*1000\n",
    "        return allocation.dot(self.mean_returns)\n",
    "    \n",
    "    def show_returns(self, allocation):\n",
    "        pass\n",
    "    \n",
    "    def view_portfolio(self,allocation,rounding = 5, zeros = False):\n",
    "        df = self.universe.filter(['TICKER','NAME','SECTOR','LOCATION'], axis=1)\n",
    "        df[\"ALLOCATION\"] = np.round(allocation,rounding)\n",
    "        if zeros == False:\n",
    "            df = df[df.ALLOCATION != 0]\n",
    "        print(\"returns:\" + str(opt.returns(allocation)))\n",
    "        print(\"variance:\" + str(opt.cost(allocation,\"volatility\")))\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def mad(self,data):\n",
    "        m = np.mean(data)\n",
    "        return np.mean(abs(m-data))\n",
    "    \n",
    "    def running_portfolio_returns(self,allocations):\n",
    "        returns = np.zeros(len(self.prices))\n",
    "        for i in range(1,len(returns)):\n",
    "            returns[i] = returns[i-1] + (self.prices[i]-self.prices[i-1]).dot(allocations[i])\n",
    "        return returns\n",
    "    # Average return from historical data given allocation of assets\n",
    "    @staticmethod\n",
    "    def mean_returns(prices,allocation,method=\"mean\"):\n",
    "        if method == \"mean\":\n",
    "            final_value = allocation.dot(prices[-1,:])\n",
    "            initial_value = allocation.dot(prices[1,:])\n",
    "            return (final_value-initial_value)/len(prices[:,0])\n",
    "        elif method == \"dailylog\":\n",
    "            values = prices.dot(allocation)\n",
    "            return np.mean(np.log(values[1:]/values[:-1]))\n",
    "        elif method == \"fulllog\":\n",
    "            final_value = allocation.dot(prices[-1,:])\n",
    "            initial_value = allocation.dot(prices[1,:])\n",
    "            return np.log(final_value/initial_value)/len(prices[:,0])\n",
    "    \n",
    "    # Naive volatility\n",
    "    @staticmethod\n",
    "    def naive_vol(prices,allocation):\n",
    "        var = np.cov(np.transpose(prices))\n",
    "        return allocation.dot(var).dot(allocation)\n",
    "    \n",
    "    @staticmethod\n",
    "    def denoised_cov(prices):\n",
    "        T = len(prices)\n",
    "        N = len(prices[0,:])\n",
    "        corr0 = np.corrcoef(np.transpose(prices))\n",
    "        eVal0,eVec0=getPCA(corr0)\n",
    "        sigma = np.sqrt(np.diag(np.cov(np.transpose(prices))))\n",
    "        q = T/N\n",
    "        eMax0,var0=findMaxEval(np.diag(eVal0),q,bWidth=.01)\n",
    "        nFacts0=max(eVal0.shape[0]-np.diag(eVal0)[::-1].searchsorted(eMax0),1)\n",
    "        corr1 = denoisedCorr(eVal0,eVec0,nFacts0)\n",
    "        return corr1*(np.outer(sigma,sigma))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae45ae70",
   "metadata": {},
   "source": [
    "## Speed/accuracy comparison of algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6296f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimiser()\n",
    "optbench = Optimiser()\n",
    "T = 1000\n",
    "\n",
    "opt.load_feather(\"eurostoxx_prices\",\"eurostoxx_universe\",T=T,N=48,normalize=True)\n",
    "optbench.load_feather(\"SXXP_Benchmark_Prices\",\"SXXP_Benchmark_Prices\",T=T,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd1ba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MINIMUM VARIANCE PORTFOLIO\n",
    "Ms = [3,4,5,6,7,8]\n",
    "a = len(Ms)\n",
    "cost = []\n",
    "runtime = []\n",
    "for M in Ms:\n",
    "    display(M)\n",
    "    times = np.zeros(5)\n",
    "    costs = np.zeros(5)\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "    #wbrute = opt.brute_cardinality(cost_func=\"volatility\",constraints=[\"longonly\",\"sum1\"],cardinality=M)\n",
    "    toc = time.perf_counter()\n",
    "    times[0] = toc-tic\n",
    "    #costs[0] = opt.cost(wbrute,\"volatility\")\n",
    "    costs[0] = 1\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "    wrandom = opt.monte_carlo_cardinality(cost_func=\"volatility\",constraints=[\"longonly\",\"sum1\"],cardinality=M,simulations=1000)\n",
    "    toc = time.perf_counter()\n",
    "    times[1] = toc-tic\n",
    "    costs[1] = opt.cost(wrandom,\"volatility\")\n",
    "\n",
    "    tic = time.perf_counter()\n",
    "    wincset = opt.cardinality_opt(M,0,0,cost_func=\"volatility\",limit_attempts=False)\n",
    "    toc = time.perf_counter()\n",
    "    times[2] = toc-tic\n",
    "    costs[2] = opt.cost(wincset,\"volatility\")\n",
    "\n",
    "    tic = time.perf_counter()\n",
    "    wincsetfast = opt.cardinality_opt(M,0,0,cost_func=\"volatility\",limit_attempts=True,attempts=5)\n",
    "    toc = time.perf_counter()\n",
    "    times[3] = toc-tic\n",
    "    costs[3] = opt.cost(wincsetfast,\"volatility\")\n",
    "\n",
    "    tic = time.perf_counter()\n",
    "    wgreedy = opt.greedy_cardinality(cost_func=\"volatility\",constraints=[\"longonly\",\"sum1\"],cardinality=M)\n",
    "    toc = time.perf_counter()\n",
    "    times[4] = toc-tic\n",
    "    costs[4] = opt.cost(wgreedy,\"volatility\")\n",
    "    cost.append(costs)\n",
    "    runtime.append(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d860cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BENCHMARK PORTFOLIO\n",
    "Ms = [5,10,15,20,25,30]\n",
    "a = len(Ms)\n",
    "cost = []\n",
    "runtime = []\n",
    "bench = np.array(optbench.prices[:,0])\n",
    "for M in Ms:\n",
    "    display(M)\n",
    "    times = np.zeros(4)\n",
    "    costs = np.zeros(4)\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "    #wbrute = opt.brute_cardinality(cost_func=\"benchmark\",constraints=[\"\"],cardinality=M,benchmark=bench)\n",
    "    toc = time.perf_counter()\n",
    "    times[0] = toc-tic\n",
    "    #costs[0] = opt.cost(wbrute,\"benchmark\")\n",
    "    costs[0] = 10\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "    wrandom = opt.monte_carlo_cardinality(cost_func=\"benchmark\",constraints=[\"\"],cardinality=M,simulations=1000,benchmark=bench)\n",
    "    toc = time.perf_counter()\n",
    "    times[1] = toc-tic\n",
    "    costs[1] = opt.cost(wrandom,\"benchmark\")\n",
    "\n",
    "    tic = time.perf_counter()\n",
    "    wl1 = opt.l1_cardinality_benchmark(constraints=[\"\"],cardinality=M,benchmark=bench)\n",
    "    toc = time.perf_counter()\n",
    "    times[2] = toc-tic\n",
    "    costs[2] = opt.cost(wl1,\"benchmark\")\n",
    "\n",
    "    tic = time.perf_counter()\n",
    "    wgreedy = opt.greedy_cardinality(cost_func=\"benchmark\",constraints=[\"\"],cardinality=M,benchmark=bench)\n",
    "    toc = time.perf_counter()\n",
    "    times[3] = toc-tic\n",
    "    costs[3] = opt.cost(wgreedy,\"benchmark\")\n",
    "    cost.append(costs)\n",
    "    runtime.append(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc5d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMPUTE AND DISPLAY ERRORS\n",
    "relcost = []\n",
    "for i in cost:\n",
    "    relcost.append((i-min(i))/min(i))\n",
    "for i in range(len(runtime)):\n",
    "    text = \"&\"\n",
    "    for j in range(len(relcost[i])):\n",
    "        text = text + str(np.round(relcost[i][j],3)) + \" (\" + str(np.round(runtime[i][j],1)) + \"s)\" + \"&\"\n",
    "    print(text[:-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3afd96",
   "metadata": {},
   "source": [
    "## Stability (allocation evolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd7a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimiser()\n",
    "optbench = Optimiser()\n",
    "T = 1000\n",
    "\n",
    "opt.load_feather(\"eurostoxx_prices\",\"eurostoxx_universe\",T=T,N=48,normalize=True)\n",
    "optbench.load_feather(\"SXXP_Benchmark_Prices\",\"SXXP_Benchmark_Prices\",T=T,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacf6b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "sample = 350\n",
    "weights = np.zeros([len(opt.assets),N])\n",
    "cardweights = np.zeros([len(opt.assets),N])\n",
    "robustweights = np.zeros([len(opt.assets),N])\n",
    "denoisedweights = np.zeros([len(opt.assets),N])\n",
    "\n",
    "bench = optbench.prices[:,0]\n",
    "M = 2\n",
    "constraints = [\"sum1\",\"longonly\"]\n",
    "\n",
    "last = len(opt.prices)-sample\n",
    "dt = last//N\n",
    "t = np.arange(N)*dt+sample\n",
    "display(t)\n",
    "sparsity=np.array([0,0,1,0,0,1,0,0,0,0])\n",
    "l = 0.0000\n",
    "\n",
    "cost = \"volatility\"\n",
    "\n",
    "cardweights[:,0] = opt.greedy_cardinality(debug=False,cardinality=M,time=[t[0]-sample,t[0]],cost_func=cost,constraints=constraints)\n",
    "weights[:,0] = opt.cvx_opt(time=[t[0]-sample,t[0]],cost_func=cost,constraints=constraints)\n",
    "robustweights[:,0] = opt.cvx_opt(time=[t[0]-sample,t[0]],cost_func=\"robust_volatility\",constraints=constraints,minreturn=0.01)\n",
    "denoisedweights[:,0] = opt.cvx_opt(time=[t[0]-sample,t[0]],cost_func=\"denoised_volatility\",constraints=constraints,minreturn=0.01)\n",
    "\n",
    "noadjustweights[:,0] = opt.cvx_opt(time=[t[0]-sample,t[0]],cost_func=\"volatility\",constraints=constraints[:2])\n",
    "for i in range(1,len(t)):\n",
    "    if i % 5 == 0:\n",
    "        print(str(i))\n",
    "    cardweights[:,i] = opt.greedy_cardinality(adjust = (cardweights[:,i-1],l),debug=False,cardinality=M,time=[t[i]-sample,t[i]],cost_func=cost,constraints=constraints)\n",
    "    weights[:,i] = opt.cvx_opt(adjust = (weights[:,i-1],l),time=[t[i]-sample,t[i]],cost_func=cost,constraints=constraints)\n",
    "    robustweights[:,i] = opt.cvx_opt(adjust = (weights[:,i-1],l),time=[t[i]-sample,t[i]],cost_func=\"robust_volatility\",constraints=constraints)\n",
    "    denoisedweights[:,i] = opt.cvx_opt(adjust = (weights[:,i-1],l),time=[t[i]-sample,t[i]],cost_func=\"denoised_volatility\",constraints=constraints)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024368fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(opt.assets)):\n",
    "    fig = px.line(labels={\"x\":\"start time (days)\",\"y\":\"portfolio weight\"})\n",
    "    \n",
    "    fig.add_scatter(x=t,y=np.round(cardweights[i,:],5),name=\"cardinality\")\n",
    "    fig.add_scatter(x=t,y=np.round(weights[i,:],5),name=\"sample\",marker = {'color' : 'blue'})\n",
    "    fig.add_scatter(x=t,y=np.round(robustweights[i,:],5),name=\"robust\",marker = {'color' : 'red'})\n",
    "    fig.add_scatter(x=t,y=np.round(denoisedweights[i,:],5),name=\"denoised\",marker = {'color' : 'green'})\n",
    "\n",
    "    fig.update_layout(title=\"Asset \" + str(i+1) + \": \" + str(opt.universe.iloc[i][\"NAME\"]),\n",
    "        font_family=\"Times New Roman\",\n",
    "        font_color=\"black\",\n",
    "        font_size=25,\n",
    "        showlegend=True\n",
    "        ,yaxis_range=[0,1]\n",
    "        )\n",
    "    fig.show()\n",
    "    #opt.view_portfolio(np.round(weights[:,-1],5))\n",
    "    #fig.write_image(\"asset\" + str(i) +\".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bf6414",
   "metadata": {},
   "source": [
    "## L1 algorithm: assets in function of lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ec194",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimiser()\n",
    "optbench = Optimiser()\n",
    "T = 1000\n",
    "opt.load_feather(\"eurostoxx_prices\",\"eurostoxx_universe\",T=T,N=48,normalize=True)\n",
    "optbench.load_feather(\"SXXP_Benchmark_Prices\",\"SXXP_Benchmark_Prices\",T=T,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319bdfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_allocation = np.ones(len(opt.assets))/len(opt.assets)\n",
    "random_allocation = np.random.uniform(0,1/len(opt.assets),len(opt.assets))\n",
    "bench_naive = opt.prices.dot(naive_allocation)\n",
    "bench_random = opt.prices.dot(random_allocation)\n",
    "bench_flat = np.ones(len(opt.prices))\n",
    "bench_line = np.arange(len(opt.prices))\n",
    "bench_wave = np.sin(np.arange(len(opt.prices))/300)*100\n",
    "\n",
    "bench = optbench.prices[:,0]\n",
    "\n",
    "params = np.logspace(-2,3,100)\n",
    "nums = []\n",
    "errs1 = []\n",
    "errs2 = []\n",
    "\n",
    "for i in params:\n",
    "    \n",
    "    minw1 = np.round(opt.cvx_opt(cost_func=\"benchmark\",constraints=[\"L1\",\"longonly\"],parameter=i,benchmark = bench),3)\n",
    "    w = opt.cvx_opt(cost_func=\"benchmark\",constraints=[\"longonly\"],benchmark=bench,sparsity=minw1)\n",
    "    nums.append(len(minw1[minw1>0]))\n",
    "    errs1.append(np.linalg.norm(opt.prices.dot(w)-bench))\n",
    "\n",
    "\n",
    "#fig.add_scatter(x=params,y=errs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d278a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmin = opt.cvx_opt(cost_func=\"benchmark\",constraints=[\"longonly\"],benchmark=bench)\n",
    "cmin = np.linalg.norm(opt.prices.dot(wmin)-bench)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca6420",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=params,y=nums,log_x=True)\n",
    "fig.add_scatter(x=params,y=(errs1-cmin)/cmin)\n",
    "fig.update_layout(title=\"Number of assets in optimal portfolio\",\n",
    "        font_family=\"Times New Roman\",\n",
    "        font_color=\"black\",\n",
    "        font_size=25,\n",
    "        xaxis_title=\"$\\lambda$\",\n",
    "        yaxis_title=\"n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e52f93",
   "metadata": {},
   "source": [
    "## Marcenko-Pastur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae24a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRndCov(nCols,nFacts):\n",
    "    w=np.random.normal(size=(nCols,nFacts))\n",
    "    cov=np.dot(w,w.T) # random cov matrix, however not full rank\n",
    "    cov+=np.diag(np.random.uniform(size=nCols)) # full rank cov\n",
    "    return cov\n",
    "\n",
    "\n",
    "alpha,N,nFact,T=.995,1000,100,20000\n",
    "cov=np.cov(np.random.normal(size=(T,N)),rowvar=0)\n",
    "cov=alpha*cov+(1-alpha)*getRndCov(N,nFact) # noise+signal\n",
    "corr0=cov2corr(cov)\n",
    "eVal0,eVec0=getPCA(corr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac86501",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = T/N\n",
    "eMax0,var0=findMaxEval(np.diag(eVal0),q,bWidth=.01)\n",
    "nFacts0=eVal0.shape[0]-np.diag(eVal0)[::-1].searchsorted(eMax0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9e1314",
   "metadata": {},
   "outputs": [],
   "source": [
    "density = mpPDF(var0,q)\n",
    "fig = px.histogram(np.diag(eVal0), histnorm='probability density',nbins=1000)\n",
    "fig.add_scatter(x=density.index,y=density)\n",
    "fig.update_layout(title=\"Eigenvalue distribution (noise+signal)\",\n",
    "        font_family=\"Times New Roman\",\n",
    "        font_color=\"black\",\n",
    "        font_size=25,\n",
    "        showlegend=False\n",
    "        ,xaxis_range=[0,8]\n",
    "        ,xaxis_title=\"$\\lambda$\"\n",
    "        ,autosize=False\n",
    "        ,width=700\n",
    "        ,height=500\n",
    "        )\n",
    "fig.show()\n",
    "#fig.write_image(\"mpnoise.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30a71fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
